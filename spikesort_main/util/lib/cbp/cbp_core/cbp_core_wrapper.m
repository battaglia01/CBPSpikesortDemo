function [TransformParams, Magnitudes, reconstructed_data, Info] = ...
    cbp_core_wrapper(data_samples, Features, pars)

% Do many examples in parallel
%
% Arguments:
%
% data_samples : cell array of data examples
% Features : cell array of features
% pars : parameters
%
% Returns:
% TransformParams : cell array estimated transformational parameters
% Magnitudes : cell array with estimated instance Magnitudes%
% reconstructed_data : cell array reconstruction of the data examples.
% Info : information (including grid points, Dictionary, raw coeffs,
%        weights - see cbp_core2.m).

% Simply wraps around cbp_core.m
if ~isfield(pars, 'progress'), pars.progress = false; end

TransformParams = cell(length(data_samples), 1);
Magnitudes = cell(size(TransformParams));
reconstructed_data = cell(size(TransformParams));
info_flag = nargout > 3;
if (info_flag)
    %fprintf('Warning: storing info. THIS COULD BE MEMORY INTENSIVE!\n');
    %fprintf('Press Enter to continue.\n');
    %pause;
    Info = cell(size(TransformParams));
end
true_spikes_flag = isfield(pars, 'true_spikes') && ...
                   ~isempty(pars.true_spikes);
if (isfield(pars, 'parfor_chunk_size'))
    PARFOR_CHUNK_SIZE = pars.parfor_chunk_size;
else
    PARFOR_CHUNK_SIZE = 1e3;
end
offset = 0;
num_chunks = max(1, ceil(length(data_samples) / PARFOR_CHUNK_SIZE));

% Process in chunks so as not to be so memory-intensive.
for chunk_num = 1:num_chunks
    chunk_idx = offset + 1 : min(length(data_samples), ...
                                 offset + PARFOR_CHUNK_SIZE);
    chunk_size = length(chunk_idx);
    T = cell(chunk_size, 1);
    M = cell(chunk_size, 1);
    R = cell(chunk_size, 1);
    if info_flag
        I = cell(chunk_size, 1);
    else
        I = [];
    end
    fprintf('\nProcessing chunk %d/%d, which contains %d snippets...\n', ...
             chunk_num, num_chunks, chunk_size);

    D = data_samples(chunk_idx);
    greedy_count = false(chunk_size, 1);
    info_flag = nargout > 3;

    numprogunits = min(50,chunk_size);
    fprintf('Progress:\n');
    fprintf('  %s\n',repmat('_',1,numprogunits));
    fprintf('  \n');
    fprintf('  %s\n',repmat(sprintf('\xAF'),1,numprogunits));
    
    %%@Picking a random seed here avoids weird issues in the progress bar
    rseed = rand;
    parfor example_num=1:chunk_size
        tic;

        pars_i = pars;
        if (true_spikes_flag)
            pars_i.true_spikes = pars.true_spikes{example_num};
        end
        if (pars_i.debug_mode)
            fprintf('\n\n\tEvaluating example %d/%d\n', ...
                    example_num, chunk_size);
        end

        [T{example_num}, ...
         M{example_num}, ...
         R{example_num}, ...
         tmp] = ...
             cbp_core2(D{example_num}, Features, pars_i);

        greedy_count(example_num) = ...
           isfield(tmp, 'greedy_soln') && ...
           tmp.greedy_soln;

        if (pars_i.debug_mode)
            fprintf('\n\n');
        end

        if (info_flag)
            I{example_num} = tmp;
        end

        eltime = toc;
        if pars_i.progress
            %%@The below rounds things and sees if we've incremented another
            %%@numprogunit. This will work even if the snippets are
            %%@processed in some random order
            changed = floor(example_num/chunk_size*numprogunits+rseed) - ...
                      floor((example_num-1)/chunk_size*numprogunits+rseed);
            if changed==1
                %%@This fprintf string advances the progress bar
                fprintf('%s|\n  %s\n',repmat(sprintf('\b'),1,...
                    numprogunits+4),repmat(sprintf('\xAF'),1,numprogunits));
            end
        end
    end

    % Copy them into the master data structures
    for i = 1 : chunk_size
        TransformParams{chunk_idx(i)} = T{i};
        Magnitudes{chunk_idx(i)} = M{i};
        reconstructed_data{chunk_idx(i)} = R{i};
        if info_flag  % Warning: memory intensive!
            Info{chunk_idx(i)} = I{i};
        end
    end
    fprintf('done.\n');
    fprintf('%d / %d (%0.3f percent) used greedy solution.\n', ...
            sum(greedy_count), chunk_size , 100 * mean(greedy_count));
    offset = chunk_idx(end);
end
