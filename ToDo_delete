%% -----------------------------------------------------------------
INTERFACE/COSMETIC CHANGES:

* unify underscores and capitalization in naming, at least for top-level
  (user-called) functions and variables!

* Get rid of old/unused functions and parameters.  EG: evaluate_sorting and EvaluateSorting (yuk!)

* add to params.plotting: DataFigureSIze, maxTracePlotLen, noiseCol, spikeCol

* Unify wording:  "snippet"/"chunk" -> "segment" ?

* demo script should run with diagnostics turned off, checking waveform convergence
  and repeating...

* Units:
  - waveform_len should be expressed in msec (waveforms typically 2-6 msec)
  - CBP firing_rate prior should be expressed in Hz (not prob per spike bin)

* VisualizeClustering:
  - show 2D subspace that best captures SPIKE WAVEFORMS and their translates.
  - show a background noise cluster?
  - give time in msec, not samples
  - show spike rates, in addition to total count
  - for waveforms, give expected MISS+FP rate, given univariate Gaussian noise
  - also give probability of mistaking each waveform for the others

* AmplitudeThresholdGUI:
 - give timescales in msec, not samples
 - show total spike counts (and rate) for each cell. 
 - add par for bin width - default 0.6msec ~ width of the main lobe of the waveforms

* Refine the GUI for inspecting results.  Specifically, user should be able to view
  voltage traces and scroll/jump to "events", including found spikes, unusually low
  amplitude found spikes, unusually large amplitude background locations, refractory
  violations, cross-corr (synchrony) artifacts, or mis-matches between two sorters
  (or sorter and ground truth).

* After running clustering (or CBP), give options to:
  merge cells (average two waveforms, reducing num_waveforms)
  split cells (specify new centroids graphically, increase num_waveforms)
  add a new (orthogonalized) random waveform


%% -----------------------------------------------------------------
SMALL ALGORITHMIC CHANGES:

* Data file should include a t0 (time of initial sample, in sec) and all times should
  be expressed/plotted relative to that.  This requires computing/correcting
  filtering lags. Yuk.

* filtering stage should also allow subsampling, if high freq limit is significantly
  below Nyquist

* filtering.pad doesn't need to be a parameter.  Left side should be
  padded by filtering.order, and right side needs order+waveform_len,
  and a bit more for IIR filtering.

* Use asymmetric window around peak for spike waveform, perhaps 3:1

* Clustering: number of PC's should be set using a better statistical criterion than
  percent_variance.  Specifically, we know what the eigenvalues of a given number of
  samples of univariate Gaussian white noise should look like, so should use only
  those that are significantly above that...

* Improve consistency of thresholding tests for spikes/noise: 
  - Filtering: globally rescales data so that max(abs) is 1.  Should rescale each
    channel separately, to try to ensure noise has equal variance.
  - Whitening: compares cross-channel L2-norm (CCN) to noise_threshold.  Probably
    better to compute L2-norm over a few time bins, and then Lp-norm across channels,
    to allow for spike waveforms that live on only one or a few channels.
  - Clustering: originally used 4*std(CCN) to grab spike segments (??).  EPS changed
    to a constant value of 6, relative to noise stdev (=1).  Preferable: User should
    set a tolerable error rate (miss+fa), provide a prior on firing rates, and
    theshold should be chosen using an SDT calculation!
      T= (log(1-pr)-log(pr) + a^2/2)/a, w/ pr=prob of spike in dt, a=spike amplitude
      eg: for error rate of 0.1%, with a prior of 1e-3, this is about 8.2
  - Partitioning (snippets): uses yet another threshold, and additionally relies on
     min_separation_length and min/max snippet length parameters.  This should
     probably be again, an L2 norm over a few times bins, then combined in an Lp norm
     over channels.

* Improve threshold determination: (1) Choose automatic thresholds by fitting a
  mixture of univariate Gaussians to the recovered amplitudes (currently uses
  matlab's function, which chooses bandwidth automatically); (2) allow multiple
  thresholds, so that similar waveforms with different amplitudes are handled
  correctly - iterating on this will require the operator-slitting method mentioned
  below,

* re-estimate all waveforms simultaneously (currently computes STA on each individually).

%% ----------------------------------------------------------------- 
MAJOR ALGORITHM MODIFICATIONS:

* Speedup: Fourier-domain convolution

* Handle noise distributions with other pnorms (stretched exponentials).  This is
  described in the paper, and the original CVX implementation did this, but we
  eliminated it when switching to ECOS.

* Allow AMPLITUDE DRIFT:
  - allow slow temporal drift of waveform amplitudes
  - allow systematic amplitude reductions in bursts based on time/ampltidue of
    previous spike.

* Make code INCREMENTAL, reading data from file and processing recursively.

* Switch to an operator-splitting optimization method (e.g., ADMM) to embed
  the final thresholding step into the iterative process.  This
  combines the best aspects of convex and greedy approaches, and will
  be both faster and potentially much more accurate! 
